{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "76434530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "59b3d923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>Beans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>Beans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>61</td>\n",
       "      <td>78</td>\n",
       "      <td>Beans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>Beans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>Beans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>118</td>\n",
       "      <td>47</td>\n",
       "      <td>77</td>\n",
       "      <td>Watermelon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>157</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>Watermelon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>144</td>\n",
       "      <td>43</td>\n",
       "      <td>77</td>\n",
       "      <td>Watermelon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>148</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>Watermelon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>Watermelon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       N   P   K       LABEL\n",
       "0     80  77  73       Beans\n",
       "1     63  73  74       Beans\n",
       "2     85  61  78       Beans\n",
       "3    116  59  54       Beans\n",
       "4     96  64  69       Beans\n",
       "..   ...  ..  ..         ...\n",
       "414  118  47  77  Watermelon\n",
       "415  157  57  66  Watermelon\n",
       "416  144  43  77  Watermelon\n",
       "417  148  47  61  Watermelon\n",
       "418  109  58  61  Watermelon\n",
       "\n",
       "[419 rows x 4 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r\"npk_new.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "bcae44c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Beans',\n",
       " 'Brinjal',\n",
       " 'Cabbage',\n",
       " 'Carrot',\n",
       " 'Cauliflower',\n",
       " 'Cowpea',\n",
       " 'Cucumber',\n",
       " 'Garden pea',\n",
       " 'Garlic',\n",
       " 'Lettuce',\n",
       " 'Okra',\n",
       " 'Onion',\n",
       " 'Potato',\n",
       " 'Snap bean',\n",
       " 'Spinach',\n",
       " 'Tomato',\n",
       " 'Watermelon']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset['LABEL'].unique().tolist()\n",
    "labels.sort()\n",
    "print(len(labels))\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "240ef7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(dataset['LABEL'])\n",
    "dataset['LABEL']=le.transform(dataset['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "a2355a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>61</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>118</td>\n",
       "      <td>47</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>157</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>144</td>\n",
       "      <td>43</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>148</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       N   P   K  LABEL\n",
       "0     80  77  73      0\n",
       "1     63  73  74      0\n",
       "2     85  61  78      0\n",
       "3    116  59  54      0\n",
       "4     96  64  69      0\n",
       "..   ...  ..  ..    ...\n",
       "414  118  47  77     16\n",
       "415  157  57  66     16\n",
       "416  144  43  77     16\n",
       "417  148  47  61     16\n",
       "418  109  58  61     16\n",
       "\n",
       "[419 rows x 4 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "257f0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# #scaler.fit(X)\n",
    "# dataset.iloc[0:,:-1] =scaler.fit_transform(dataset.iloc[0:,:-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "76269afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 80  77  73]\n",
      " [ 63  73  74]\n",
      " [ 85  61  78]\n",
      " ...\n",
      " [144  43  77]\n",
      " [148  47  61]\n",
      " [109  58  61]]\n",
      "     LABEL\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "..     ...\n",
      "414     16\n",
      "415     16\n",
      "416     16\n",
      "417     16\n",
      "418     16\n",
      "\n",
      "[419 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# selecting the features and labels\n",
    "X = dataset.iloc[:, :-1].values\n",
    "Y = dataset.loc[:, ['LABEL']]\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting the model into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.25, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "5c98ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=['Beans',\n",
    " 'Brinjal',\n",
    " 'Cabbage',\n",
    " 'Carrot',\n",
    " 'Cauliflower',\n",
    " 'Chilli',\n",
    " 'Cowpea',\n",
    " 'Cucumber',\n",
    " 'Garden pea',\n",
    " 'Garlic',\n",
    " 'Lettuce',\n",
    " 'Okra',\n",
    " 'Onion',\n",
    " 'Potato',\n",
    " 'Snap bean',\n",
    " 'Spinach',\n",
    " 'Tomato',\n",
    " 'Watermelon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b8914853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAMILA\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************************\n",
      "Accuracy = 0.21904761904761905\n",
      "***********************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # training a logistics regression model\n",
    "# logmodel = LogisticRegression()\n",
    "# logmodel.fit(X_train, y_train.values.ravel())\n",
    "# predictions = logmodel.predict(X_test)\n",
    "# print(\"***********************************************************\")\n",
    "# print(\"Accuracy = \" + str(accuracy_score(y_test.values.ravel(), predictions)))\n",
    "# print(\"***********************************************************\")\n",
    "\n",
    "sgd_classifier = SGDClassifier(tol=-np.infty, loss='log')\n",
    "sgd_classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = sgd_classifier.predict(X_test)\n",
    "print(\"***********************************************************\")\n",
    "print(\"Accuracy = \" + str(accuracy_score(y_test.values.ravel(), predictions)))\n",
    "print(\"***********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "162a423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "Cabbage\n"
     ]
    }
   ],
   "source": [
    "test_data=[[100,500,50]]\n",
    "o=sgd_classifier.predict(test_data)\n",
    "print(o)\n",
    "print(result[int(o[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "76d1bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************************\n",
      "0.8998393430910416\n",
      "***********************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    " \n",
    " # create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 200, random_state = 32)\n",
    " \n",
    "# fit the regressor with x and y data\n",
    "regressor.fit(X_train, y_train.values.ravel())\n",
    "predictions = regressor.predict(X_train)\n",
    "print(\"***********************************************************\")\n",
    "\n",
    "print(regressor.score(X_train, y_train))\n",
    "\n",
    "print(\"***********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6f6f4ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(regressor, open('randomforest_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "551f3dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Onion'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f0dca086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.655]\n",
      "Okra\n"
     ]
    }
   ],
   "source": [
    "test_data=[[200,59,70]]\n",
    "#print(regressor.predict([[]]))\n",
    "\n",
    "# Loading model to compare the results\n",
    "regressor = pickle.load(open('randomforest_model.pkl','rb'))\n",
    "o=regressor.predict(test_data)\n",
    "print(o)\n",
    "print(labels[round(o[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "27bfbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(sgd_classifier.predict_proba([[137,42,144]]).transpose())\n",
    "results.rename(columns={0: \"score\"}, inplace=True)\n",
    "\n",
    "results.reset_index(level=0, inplace=True)\n",
    "results.sort_values(by=\"score\", ascending=False, inplace=True, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "13920223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watermelon (33%)\n",
      "Carrot (33%)\n",
      "Potato (33%)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "    if results.loc[i, \"score\"] > 0.001:\n",
    "        print(str(labels[results.loc[i, \"index\"]]) + \" (\" + str(round(100 * results.loc[i, \"score\"])) + \"%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "45d90aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7113f951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       N   P   K       LABEL\n",
      "0     80  77  73       Beans\n",
      "1     63  73  74       Beans\n",
      "2     85  61  78       Beans\n",
      "3    116  59  54       Beans\n",
      "4     96  64  69       Beans\n",
      "..   ...  ..  ..         ...\n",
      "420  118  47  77  Watermelon\n",
      "421  157  57  66  Watermelon\n",
      "422  144  43  77  Watermelon\n",
      "423  148  47  61  Watermelon\n",
      "424  109  58  61  Watermelon\n",
      "\n",
      "[425 rows x 4 columns]\n",
      "(425, 3)\n",
      "(425,)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "df = pd.read_csv(r\"npk_new.csv\")\n",
    "print(df)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['LABEL'])\n",
    "df['LABEL']=le.transform(df['LABEL'])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler.fit(X)\n",
    "df.iloc[0:,:-1] =scaler.fit_transform(df.iloc[0:,:-1]) \n",
    "\n",
    "X=df.drop('LABEL',axis=1)\n",
    "Y=df['LABEL']\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "065df807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 3)\n",
      "(425,)\n",
      "            N         P         K  LABEL\n",
      "0   -1.217038  1.067362  0.289705      0\n",
      "1   -1.632572  0.739477  0.353467      0\n",
      "2   -1.094823 -0.244178  0.608516      0\n",
      "3   -0.337085 -0.408120 -0.921775      0\n",
      "4   -0.825948  0.001736  0.034657      0\n",
      "..        ...       ...       ...    ...\n",
      "420 -0.288199 -1.391775  0.544753     16\n",
      "421  0.665083 -0.572063 -0.156630     16\n",
      "422  0.347323 -1.719660  0.544753     16\n",
      "423  0.445095 -1.391775 -0.475440     16\n",
      "424 -0.508187 -0.490091 -0.475440     16\n",
      "\n",
      "[425 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2aeb26d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 1, 3)\n",
      "(425, 17)\n",
      "(340, 1, 3)\n",
      "(85, 1, 3)\n",
      "(340, 17)\n",
      "(85, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nb_class=17\n",
    "\n",
    "X = np.expand_dims(X,axis=1)\n",
    "Y = to_categorical(Y, nb_class)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "Y\n",
    "\n",
    "X\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.2, random_state=100)\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)\n",
    "\n",
    "\n",
    "\n",
    "nb_timesteps=X.shape[2]\n",
    "nb_timesteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5d107211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 7s 154ms/step - loss: 2.8103 - accuracy: 0.1294 - val_loss: 2.7964 - val_accuracy: 0.1529\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7604 - accuracy: 0.2294 - val_loss: 2.7536 - val_accuracy: 0.1882\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.7084 - accuracy: 0.2559 - val_loss: 2.7077 - val_accuracy: 0.1882\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.6519 - accuracy: 0.2559 - val_loss: 2.6550 - val_accuracy: 0.1882\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.5868 - accuracy: 0.2500 - val_loss: 2.5970 - val_accuracy: 0.1882\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5180 - accuracy: 0.2529 - val_loss: 2.5332 - val_accuracy: 0.2000\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.4423 - accuracy: 0.2500 - val_loss: 2.4713 - val_accuracy: 0.2000\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 2.3696 - accuracy: 0.2529 - val_loss: 2.4120 - val_accuracy: 0.2118\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3009 - accuracy: 0.2559 - val_loss: 2.3581 - val_accuracy: 0.2118\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2390 - accuracy: 0.2618 - val_loss: 2.3090 - val_accuracy: 0.2235\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 2.1845 - accuracy: 0.2765 - val_loss: 2.2674 - val_accuracy: 0.2235\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1357 - accuracy: 0.2765 - val_loss: 2.2277 - val_accuracy: 0.2235\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.0914 - accuracy: 0.2941 - val_loss: 2.1929 - val_accuracy: 0.2235\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.0533 - accuracy: 0.3176 - val_loss: 2.1611 - val_accuracy: 0.2353\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.0164 - accuracy: 0.3294 - val_loss: 2.1293 - val_accuracy: 0.2353\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.9822 - accuracy: 0.3588 - val_loss: 2.1032 - val_accuracy: 0.2471\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.9521 - accuracy: 0.3647 - val_loss: 2.0777 - val_accuracy: 0.2706\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.9245 - accuracy: 0.3824 - val_loss: 2.0567 - val_accuracy: 0.2941\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.8978 - accuracy: 0.3765 - val_loss: 2.0367 - val_accuracy: 0.3059\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.8750 - accuracy: 0.3882 - val_loss: 2.0161 - val_accuracy: 0.3059\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.8522 - accuracy: 0.3912 - val_loss: 1.9967 - val_accuracy: 0.2706\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.8319 - accuracy: 0.3853 - val_loss: 1.9772 - val_accuracy: 0.2588\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.8111 - accuracy: 0.3971 - val_loss: 1.9578 - val_accuracy: 0.2824\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.7935 - accuracy: 0.4000 - val_loss: 1.9452 - val_accuracy: 0.2471\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.7765 - accuracy: 0.4000 - val_loss: 1.9307 - val_accuracy: 0.2353\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.7608 - accuracy: 0.3971 - val_loss: 1.9177 - val_accuracy: 0.2353\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.7443 - accuracy: 0.4088 - val_loss: 1.9034 - val_accuracy: 0.2706\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.7300 - accuracy: 0.4176 - val_loss: 1.8891 - val_accuracy: 0.2706\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.7153 - accuracy: 0.4147 - val_loss: 1.8734 - val_accuracy: 0.2706\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.7014 - accuracy: 0.4324 - val_loss: 1.8594 - val_accuracy: 0.3059\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.6878 - accuracy: 0.4441 - val_loss: 1.8474 - val_accuracy: 0.3176\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.6761 - accuracy: 0.4471 - val_loss: 1.8377 - val_accuracy: 0.3059\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.6632 - accuracy: 0.4500 - val_loss: 1.8294 - val_accuracy: 0.3059\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.6527 - accuracy: 0.4559 - val_loss: 1.8200 - val_accuracy: 0.3176\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.6419 - accuracy: 0.4588 - val_loss: 1.8088 - val_accuracy: 0.3176\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.6309 - accuracy: 0.4618 - val_loss: 1.7954 - val_accuracy: 0.3176\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.6209 - accuracy: 0.4529 - val_loss: 1.7862 - val_accuracy: 0.3176\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.6123 - accuracy: 0.4500 - val_loss: 1.7743 - val_accuracy: 0.2824\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.6038 - accuracy: 0.4559 - val_loss: 1.7624 - val_accuracy: 0.3176\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5946 - accuracy: 0.4588 - val_loss: 1.7546 - val_accuracy: 0.3176\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5857 - accuracy: 0.4618 - val_loss: 1.7512 - val_accuracy: 0.3176\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5786 - accuracy: 0.4706 - val_loss: 1.7447 - val_accuracy: 0.3294\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5728 - accuracy: 0.4647 - val_loss: 1.7369 - val_accuracy: 0.3412\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5687 - accuracy: 0.4676 - val_loss: 1.7271 - val_accuracy: 0.3412\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5597 - accuracy: 0.4647 - val_loss: 1.7236 - val_accuracy: 0.3529\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5519 - accuracy: 0.4706 - val_loss: 1.7159 - val_accuracy: 0.3412\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5474 - accuracy: 0.4618 - val_loss: 1.7108 - val_accuracy: 0.3412\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5436 - accuracy: 0.4647 - val_loss: 1.7129 - val_accuracy: 0.3765\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5367 - accuracy: 0.4706 - val_loss: 1.7045 - val_accuracy: 0.3647\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.5317 - accuracy: 0.4618 - val_loss: 1.6980 - val_accuracy: 0.3294\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5264 - accuracy: 0.4647 - val_loss: 1.6930 - val_accuracy: 0.3412\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5223 - accuracy: 0.4706 - val_loss: 1.6900 - val_accuracy: 0.3529\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5178 - accuracy: 0.4676 - val_loss: 1.6884 - val_accuracy: 0.3412\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5145 - accuracy: 0.4794 - val_loss: 1.6824 - val_accuracy: 0.3529\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.5085 - accuracy: 0.4794 - val_loss: 1.6832 - val_accuracy: 0.3529\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5049 - accuracy: 0.4706 - val_loss: 1.6795 - val_accuracy: 0.3647\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5013 - accuracy: 0.4735 - val_loss: 1.6752 - val_accuracy: 0.3529\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4990 - accuracy: 0.4676 - val_loss: 1.6691 - val_accuracy: 0.3412\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4955 - accuracy: 0.4706 - val_loss: 1.6671 - val_accuracy: 0.3412\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4929 - accuracy: 0.4706 - val_loss: 1.6622 - val_accuracy: 0.3412\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.4877 - accuracy: 0.4676 - val_loss: 1.6592 - val_accuracy: 0.3412\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4866 - accuracy: 0.4794 - val_loss: 1.6530 - val_accuracy: 0.3412\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.4825 - accuracy: 0.4882 - val_loss: 1.6476 - val_accuracy: 0.3529\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4787 - accuracy: 0.4824 - val_loss: 1.6475 - val_accuracy: 0.3529\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4755 - accuracy: 0.4794 - val_loss: 1.6482 - val_accuracy: 0.3412\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.4744 - accuracy: 0.4735 - val_loss: 1.6451 - val_accuracy: 0.3412\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4700 - accuracy: 0.4794 - val_loss: 1.6421 - val_accuracy: 0.3412\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4669 - accuracy: 0.4882 - val_loss: 1.6387 - val_accuracy: 0.3412\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4643 - accuracy: 0.4912 - val_loss: 1.6369 - val_accuracy: 0.3412\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4651 - accuracy: 0.4794 - val_loss: 1.6271 - val_accuracy: 0.3412\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4592 - accuracy: 0.4824 - val_loss: 1.6271 - val_accuracy: 0.3529\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4573 - accuracy: 0.4765 - val_loss: 1.6256 - val_accuracy: 0.3412\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4559 - accuracy: 0.4824 - val_loss: 1.6300 - val_accuracy: 0.3647\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4555 - accuracy: 0.4706 - val_loss: 1.6204 - val_accuracy: 0.3647\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4506 - accuracy: 0.4794 - val_loss: 1.6222 - val_accuracy: 0.3529\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.4480 - accuracy: 0.4853 - val_loss: 1.6232 - val_accuracy: 0.3765\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4470 - accuracy: 0.4882 - val_loss: 1.6222 - val_accuracy: 0.3647\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4445 - accuracy: 0.4941 - val_loss: 1.6195 - val_accuracy: 0.3412\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.4432 - accuracy: 0.4971 - val_loss: 1.6125 - val_accuracy: 0.3412\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4403 - accuracy: 0.4882 - val_loss: 1.6106 - val_accuracy: 0.3765\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4378 - accuracy: 0.4941 - val_loss: 1.6083 - val_accuracy: 0.3647\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4367 - accuracy: 0.4853 - val_loss: 1.6068 - val_accuracy: 0.3529\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4334 - accuracy: 0.4824 - val_loss: 1.6056 - val_accuracy: 0.3529\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.4320 - accuracy: 0.4824 - val_loss: 1.6069 - val_accuracy: 0.3529\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4310 - accuracy: 0.4765 - val_loss: 1.6053 - val_accuracy: 0.3529\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4280 - accuracy: 0.4882 - val_loss: 1.6018 - val_accuracy: 0.3529\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4270 - accuracy: 0.4882 - val_loss: 1.6008 - val_accuracy: 0.3529\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4251 - accuracy: 0.4882 - val_loss: 1.5992 - val_accuracy: 0.3529\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4218 - accuracy: 0.4912 - val_loss: 1.6009 - val_accuracy: 0.3529\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4198 - accuracy: 0.4882 - val_loss: 1.5968 - val_accuracy: 0.3529\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 1.4176 - accuracy: 0.4882 - val_loss: 1.5962 - val_accuracy: 0.3529\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4170 - accuracy: 0.4853 - val_loss: 1.5939 - val_accuracy: 0.3529\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4150 - accuracy: 0.4912 - val_loss: 1.5914 - val_accuracy: 0.3647\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4132 - accuracy: 0.4882 - val_loss: 1.5945 - val_accuracy: 0.3412\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.4123 - accuracy: 0.4882 - val_loss: 1.5975 - val_accuracy: 0.3647\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4094 - accuracy: 0.4882 - val_loss: 1.5935 - val_accuracy: 0.3529\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4080 - accuracy: 0.4882 - val_loss: 1.5929 - val_accuracy: 0.3529\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4070 - accuracy: 0.4882 - val_loss: 1.5889 - val_accuracy: 0.3529\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4044 - accuracy: 0.4882 - val_loss: 1.5897 - val_accuracy: 0.3529\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4035 - accuracy: 0.4853 - val_loss: 1.5891 - val_accuracy: 0.3647\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4014 - accuracy: 0.5088 - val_loss: 1.5895 - val_accuracy: 0.3765\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3986 - accuracy: 0.5029 - val_loss: 1.5855 - val_accuracy: 0.3765\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3984 - accuracy: 0.4971 - val_loss: 1.5822 - val_accuracy: 0.3765\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3965 - accuracy: 0.5029 - val_loss: 1.5807 - val_accuracy: 0.3647\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3981 - accuracy: 0.4971 - val_loss: 1.5819 - val_accuracy: 0.3647\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3950 - accuracy: 0.4941 - val_loss: 1.5798 - val_accuracy: 0.3765\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3925 - accuracy: 0.5088 - val_loss: 1.5810 - val_accuracy: 0.3647\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3920 - accuracy: 0.4971 - val_loss: 1.5778 - val_accuracy: 0.3765\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3902 - accuracy: 0.5000 - val_loss: 1.5780 - val_accuracy: 0.3647\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3884 - accuracy: 0.4971 - val_loss: 1.5777 - val_accuracy: 0.3765\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3868 - accuracy: 0.4941 - val_loss: 1.5771 - val_accuracy: 0.3765\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3844 - accuracy: 0.4971 - val_loss: 1.5768 - val_accuracy: 0.3529\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3846 - accuracy: 0.4941 - val_loss: 1.5831 - val_accuracy: 0.3882\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3826 - accuracy: 0.5000 - val_loss: 1.5739 - val_accuracy: 0.3765\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3798 - accuracy: 0.5118 - val_loss: 1.5765 - val_accuracy: 0.3882\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3793 - accuracy: 0.5088 - val_loss: 1.5738 - val_accuracy: 0.3647\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3765 - accuracy: 0.5059 - val_loss: 1.5753 - val_accuracy: 0.3765\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3760 - accuracy: 0.5059 - val_loss: 1.5747 - val_accuracy: 0.3647\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3743 - accuracy: 0.5059 - val_loss: 1.5722 - val_accuracy: 0.3647\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3735 - accuracy: 0.5088 - val_loss: 1.5708 - val_accuracy: 0.3765\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3726 - accuracy: 0.5118 - val_loss: 1.5688 - val_accuracy: 0.3765\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3706 - accuracy: 0.5118 - val_loss: 1.5657 - val_accuracy: 0.3765\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3691 - accuracy: 0.5088 - val_loss: 1.5653 - val_accuracy: 0.3765\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3683 - accuracy: 0.5088 - val_loss: 1.5688 - val_accuracy: 0.3765\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3670 - accuracy: 0.5147 - val_loss: 1.5680 - val_accuracy: 0.4000\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3659 - accuracy: 0.5147 - val_loss: 1.5648 - val_accuracy: 0.3765\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3650 - accuracy: 0.5176 - val_loss: 1.5660 - val_accuracy: 0.3765\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3638 - accuracy: 0.5088 - val_loss: 1.5659 - val_accuracy: 0.3765\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3607 - accuracy: 0.5147 - val_loss: 1.5676 - val_accuracy: 0.3765\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3608 - accuracy: 0.5176 - val_loss: 1.5662 - val_accuracy: 0.4000\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3589 - accuracy: 0.5176 - val_loss: 1.5650 - val_accuracy: 0.3882\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.3580 - accuracy: 0.5147 - val_loss: 1.5656 - val_accuracy: 0.4000\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3584 - accuracy: 0.5088 - val_loss: 1.5700 - val_accuracy: 0.3647\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3575 - accuracy: 0.5118 - val_loss: 1.5629 - val_accuracy: 0.3765\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3551 - accuracy: 0.5176 - val_loss: 1.5652 - val_accuracy: 0.3882\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3552 - accuracy: 0.5118 - val_loss: 1.5661 - val_accuracy: 0.3647\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3530 - accuracy: 0.5235 - val_loss: 1.5680 - val_accuracy: 0.3765\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3506 - accuracy: 0.5206 - val_loss: 1.5680 - val_accuracy: 0.3529\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3514 - accuracy: 0.5147 - val_loss: 1.5677 - val_accuracy: 0.3765\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3483 - accuracy: 0.5176 - val_loss: 1.5667 - val_accuracy: 0.3765\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.3504 - accuracy: 0.5176 - val_loss: 1.5685 - val_accuracy: 0.3765\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.3492 - accuracy: 0.5147 - val_loss: 1.5646 - val_accuracy: 0.3882\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3446 - accuracy: 0.5147 - val_loss: 1.5601 - val_accuracy: 0.4000\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.3458 - accuracy: 0.5118 - val_loss: 1.5619 - val_accuracy: 0.3882\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3448 - accuracy: 0.5265 - val_loss: 1.5636 - val_accuracy: 0.3882\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.3425 - accuracy: 0.5235 - val_loss: 1.5547 - val_accuracy: 0.3765\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3430 - accuracy: 0.5206 - val_loss: 1.5553 - val_accuracy: 0.3765\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3404 - accuracy: 0.5235 - val_loss: 1.5480 - val_accuracy: 0.3882\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3406 - accuracy: 0.5265 - val_loss: 1.5493 - val_accuracy: 0.4000\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3378 - accuracy: 0.5235 - val_loss: 1.5526 - val_accuracy: 0.4118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#LSTM\n",
    "epochs=150\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(1, nb_timesteps)))\n",
    "model.add(Dense(nb_class,activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "#history = model.fit(trainX, trainY, epochs=150, batch_size=100, validation_data=(testX, testY), verbose=0, shuffle=False)\n",
    "\n",
    "history=model.fit(xtrain, ytrain, epochs=epochs, batch_size=30, validation_data=(xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "448fbc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "model.save('lstm_model.h5')\n",
    "model =tensorflow.keras.models.load_model('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "57407b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=['Beans',\n",
    " 'Brinjal',\n",
    " 'Cabbage',\n",
    " 'Carrot',\n",
    " 'Cauliflower',\n",
    " 'Chilli',\n",
    " 'Cowpea',\n",
    " 'Cucumber',\n",
    " 'Garden pea',\n",
    " 'Garlic',\n",
    " 'Lettuce',\n",
    " 'Okra',\n",
    " 'Onion',\n",
    " 'Potato',\n",
    " 'Snap bean',\n",
    " 'Spinach',\n",
    " 'Tomato',\n",
    " 'Watermelon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5ae3ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[[1.6474480e-13 1.4375312e-04 2.8041068e-11 1.2967738e-03 1.3796043e-05\n",
      "  1.7659418e-12 3.3267689e-13 6.5825343e-14 2.6332276e-09 3.6484052e-10\n",
      "  1.2283412e-11 7.6126473e-11 9.9849522e-01 7.5307295e-12 6.3873620e-15\n",
      "  5.0425340e-05 2.1601143e-12]]\n",
      "17\n",
      "12\n",
      "Onion\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "test_data = np.array([[0,0,90]])\n",
    "lstm_model =tf.keras.models.load_model('lstm_model.h5')\n",
    "o=lstm_model.predict(test_data.reshape(-1,1,3), batch_size=1)\n",
    "\n",
    "print(o)\n",
    "print(len(o[0]))\n",
    "print(o.argmax())\n",
    "print(result[int(o.argmax())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca700e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d2bfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
